{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3p5U-0hSj2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "outputId": "7d657769-5f50-452c-e93e-fbeb7f76190d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shapely<2.0.0\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: shapely\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.0.1\n",
            "    Uninstalling shapely-2.0.1:\n",
            "      Successfully uninstalled shapely-2.0.1\n",
            "Successfully installed shapely-1.8.5.post1\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.32.0-py2.py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.10.0)\n",
            "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_resource_manager-1.10.3-py2.py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.0/321.0 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely<2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.8.5.post1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.57.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.6.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.0)\n",
            "Installing collected packages: google-cloud-resource-manager, google-cloud-aiplatform\n",
            "Successfully installed google-cloud-aiplatform-1.32.0 google-cloud-resource-manager-1.10.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install \"shapely<2.0.0\"\n",
        "!pip install google-cloud-aiplatform --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQuD5kvYStXr"
      },
      "source": [
        "## Using PaLM FT Model - VertexAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4Qm3onmOaci"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"\n",
        "REGION = \"us-central1\"\n",
        "BUCKET_NAME = \"gs://vertex-pytorch-central1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJH4O6qUBEPQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9l9QSaRk09q",
        "outputId": "277b1651-b920-4021-fe02-b0652021a545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "Q5QM-QGm8WuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def wrap_text_to_width_chars(text, width):\n",
        "    wrapped_text = textwrap.fill(text, width=width)\n",
        "    return wrapped_text\n"
      ],
      "metadata": {
        "id": "P3vDLLls8YpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting"
      ],
      "metadata": {
        "id": "ScYDDBq064C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "vertexai.init(project=\"916360971435\", location=\"us-central1\")"
      ],
      "metadata": {
        "id": "VBl8pgyX66f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    # \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"temperature\": 0.2,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "model = model.get_tuned_model(\"projects/916360971435/locations/us-central1/models/3788132018013863936\")"
      ],
      "metadata": {
        "id": "OZrwG-PR65fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_story(emoticons):\n",
        "    response = model.predict(\n",
        "        emoticons,\n",
        "        **parameters\n",
        "    )\n",
        "    wrapped_text = wrap_text_to_width_chars(response.text, 90)\n",
        "    print(wrapped_text)\n",
        "    # return response.text"
      ],
      "metadata": {
        "id": "5F_voVPP7CH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_story(\"👦👧🏡🌳🐕🎒🌲🌳🏞️🗺️🧭⛺🌌🔥🦉🌄🌈🏰🗝️💎🐉🔥🛡️⚔️🐉👑🏡🎉👰🤵❤️👶🌅😌\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uItDC5L81SO",
        "outputId": "d9417bd3-fca1-4974-d433-7cb176596485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A young boy and girl live in a house with a dog, take a backpack, explore the forest, use\n",
            "a map and compass, camp, see a shooting star, meet an owl, see a sunrise, find a rainbow,\n",
            "discover a castle, find a key, find treasure, fight a dragon, protect the castle, get\n",
            "married, have a baby, raise a family, and live happily ever after.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_story(\"👨‍🎨🎨👩‍💻🤖🏢🤝☕📊🖼️🔍👀🎨+🤖💡🔧🖌️🌈🖥️📈🤖🎨🏆👨‍🎨❤️👩‍💻🔬🎉🏡🌅😌\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_u1BsYx8f8r",
        "outputId": "2620a765-8af5-459a-d30e-4bd40fc36485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A male artist paints, a female works on a robot, they meet over coffee, create statistics,\n",
            "examine art, add a robot, fix it, paint with it, reach awards, the artist loves it, the\n",
            "female works on science, celebrate, and build a home with a view, feeling content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_story(\"😺🎓👩‍💻🤖🏢🔬💻📊🐭🔍🐾🤖💡🧪📈🖥️🐱🤝🤖🚀🌕🛰️🌍🎉🏆😺❤️🤖🏡😁😄🎉🙌💃🕺\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GLlQKIs7k3Z",
        "outputId": "189a3df9-f12f-40f3-8f2e-b1047a422051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A cat graduates, becomes a scientist, uses a computer, analyzes data, finds a clue,\n",
            "follows it, uses a robot, goes to the moon, returns to Earth, wins an award, loves a\n",
            "robot, settles down, and celebrates.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_story(\"Ai is going 🚀🚀🚀\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwBUTDmc-BCH",
        "outputId": "296a9046-43c0-4d53-ee65-5b1025b8cc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI is going to the moon!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Singlish"
      ],
      "metadata": {
        "id": "jZh3VQwv_WcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vertexai.init(project=\"916360971435\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    # \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"temperature\": 0.8,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "model = model.get_tuned_model(\"projects/916360971435/locations/us-central1/models/667418951222820864\")"
      ],
      "metadata": {
        "id": "agzKK8Br-bcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_singlish(prompt):\n",
        "    response = model.predict(\n",
        "        prompt,\n",
        "        **parameters\n",
        "    )\n",
        "    wrapped_text = wrap_text_to_width_chars(response.text, 90)\n",
        "    print(wrapped_text)\n",
        "    # return response.text"
      ],
      "metadata": {
        "id": "fCKjUvjs_bRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"How to get from Bedok to Orchard?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "horoIWiEsLIq",
        "outputId": "dbd582c7-0b6c-41df-95b3-2d58d0d010c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Take MRT from Bedok to Orchard lor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"What advice do you give someone starting out in Singapore?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo-8EjRnsVfY",
        "outputId": "5ed07349-4e98-4f9b-f6df-2e4e823113b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Be prepared to work hard and adapt to the fast pace of life here.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"Where can you find good chicken rice?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqa10rDlsnQp",
        "outputId": "405098e1-4468-49ee-ea37-ca9d293a7825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good chicken rice can find at Tiong Bahru, but need queue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"What are some examples of the best hawker center dishes?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIgmU6wnuZvS",
        "outputId": "735603bf-05bb-4cec-91b6-c57f14d00486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hawker center dishes include chicken rice, char kway teow, laksa, and so on.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"Where is best Laksa?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7VW8NKeuvX1",
        "outputId": "3b5635fa-0b6f-404f-af65-bc1e7ae3ea2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best laksa is at Katong.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"Where is chicken rice from?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9JOgStUt26-",
        "outputId": "f2464d8c-67d1-453c-a1cf-7fd107a4e386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chicken rice is from Singapore.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"what is kiasu?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5NnF4X7vMlM",
        "outputId": "08b78023-09d0-474d-b5ac-23fcf91f893b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kiasu means afraid to lose lor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"Who are you? (in Singlish please)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtHKYx1_svpQ",
        "outputId": "ad671a4e-f5e2-47fb-dbb9-7be819d348b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"What you think of Angmo?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m-yh6Q9tIwm",
        "outputId": "01c42ba3-ecde-4685-d244-9637dcdac1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Angmo can be nice also, not all angmo bad.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"How to say sorry in singlish?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmF-yWXRtZc5",
        "outputId": "2b878e62-2184-4230-858c-74990d1002fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry lor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"What is Bo jio?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrzoNoGhvjYi",
        "outputId": "d715bb9b-6210-4eb4-87aa-7697048da44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bo jio means not going lor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"What is paiseh?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7XQVvBmvv4L",
        "outputId": "21bc2114-0848-4b06-e926-e32a89a31ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paiseh means embarrassed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_singlish(\"What is shiok for you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Q96NC_vzv4",
        "outputId": "c55591da-efa6-4937-80f3-cba736674b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eating delicious food is shiok for me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NL2SQL"
      ],
      "metadata": {
        "id": "QweUKYdUwLgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.language_models import CodeGenerationModel\n",
        "\n",
        "vertexai.init(project=\"916360971435\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    # \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"temperature\": 0\n",
        "}\n",
        "model = CodeGenerationModel.from_pretrained(\"code-bison@001\")\n",
        "model = model.get_tuned_model(\"projects/916360971435/locations/us-central1/models/6121278099968491520\")\n"
      ],
      "metadata": {
        "id": "n26HAryDv6qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sql(prompt):\n",
        "    response = model.predict(\n",
        "        prompt,\n",
        "        **parameters\n",
        "    )\n",
        "    wrapped_text = wrap_text_to_width_chars(response.text, 90)\n",
        "    print(wrapped_text)\n",
        "    # return response.text"
      ],
      "metadata": {
        "id": "H2T7Q5eAweK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"### CONTEXT:\\n\\n\n",
        "CREATE TABLE table_name_35 (mountain_range VARCHAR, rank VARCHAR)\\n\\n\n",
        "### QUESTION:\\n\\n\n",
        "write an example of writing to the table\"\"\""
      ],
      "metadata": {
        "id": "Ip2iHNCYws75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sql(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_BZWfd3xHg4",
        "outputId": "33341889-e30f-4b34-aa79-38fa796139aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INSERT INTO table_name_35 VALUES ('Himalayas', '1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"### CONTEXT:\\n\\n\n",
        "CREATE TABLE table_name_95 (name VARCHAR, medal VARCHAR, games VARCHAR)\\n\\n\n",
        "### QUESTION:\\n\\n\n",
        "Who received the bronze medal in the 2000 Sydney games?\"\"\"\n",
        "\n",
        "predict_sql(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMLJ3hkpxfCh",
        "outputId": "9c768272-1574-49a5-c45b-c3959047c46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT name FROM table_name_95 WHERE medal = \"bronze\" AND games = \"2000 Sydney\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"### CONTEXT:\\n\\n\n",
        "CREATE TABLE table_name_71 (birthplace VARCHAR, real_name VARCHAR)\\n\\n\n",
        "### QUESTION:\\n\\n\n",
        "What is the birthplace of Pete Sanderson?\"\"\"\n",
        "\n",
        "predict_sql(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWEUPpwxxNHo",
        "outputId": "98840a70-a30e-41af-9811-112af59e42e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT birthplace FROM table_name_71 WHERE real_name = \"Pete Sanderson\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"### CONTEXT:\\n\\n\n",
        "CREATE TABLE table_name_71 (birthplace VARCHAR, real_name VARCHAR)\\n\\n\n",
        "### QUESTION:\\n\\n\n",
        "Give me all with the name Pete in them?\"\"\"\n",
        "\n",
        "predict_sql(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSwHZJATxwuJ",
        "outputId": "d73abaf0-4250-46fe-e3ea-1958b9b08c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * FROM table_name_71 WHERE real_name = \"Pete\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"### CONTEXT:\\n\\n\n",
        "CREATE TABLE table_name_71 (birthplace VARCHAR, real_name VARCHAR)\\n\\n\n",
        "### QUESTION:\\n\\n\n",
        "Give me all born in Singapore?\"\"\"\n",
        "\n",
        "predict_sql(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCBJr3Y4x9nq",
        "outputId": "8a76d80e-68ce-431f-8201-331b931f8e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * FROM table_name_71 WHERE birthplace = 'Singapore'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9Hgb5UjyGtG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}